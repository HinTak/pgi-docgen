#!/usr/bin/python3
# Copyright 2015,2017 Christoph Reiter
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.

from __future__ import print_function

import sys
import argparse
import json
from urllib.parse import unquote

import requests
from bs4 import BeautifulSoup
from multiprocessing import Pool

from pgidocgen.girdata import get_docref_path
from pgidocgen.girdata.library import LIBRARIES


def fetch_pages(lib):
    pages = set()
    keywords = set()
    r = requests.get(lib.devhelp_url)
    soup = BeautifulSoup(r.text, "html.parser")

    for tag in soup.findAll("sub"):
        page = tag["link"]
        if page.startswith(("index-", "api-index-",
                            "annotation-glossary", "ix")):
            continue
        if "#" in page:
            continue
        pages.add(page)

    for tag in soup.findAll("keyword"):
        if tag.get("link"):
            if tag["link"].startswith('gdbus-'):
                continue
            keywords.add(tag["link"])

    return pages, keywords


def fetch_page(arg):
    lib, page, keywords = arg

    names = {}
    r = requests.get(lib.url + page)
    soup = BeautifulSoup(r.text, "html.parser")
    for link in soup.findAll("a"):
        if not link.get("name"):
            continue
        if "." in link["name"]:
            # Mostly, links containing dots are noise. Except for links
            # generated by gdbus-codegen, which look like that:
            #     <link linkend="gdbus-method-%s.%s">
            if not link["name"].startswith('gdbus-'):
                continue
        url = page + "#" + link["name"]
        if url not in keywords:
            names[unquote(link["name"])] = lib.url + url
    return names, page


def main(argv):
    pool = Pool(20)

    parser = argparse.ArgumentParser(description='Fetch docrefs')
    parser.add_argument('namespace', nargs="*",
                        help='namespace including version e.g. Gtk-3.0')

    try:
        args = parser.parse_args(argv[1:])
    except SystemExit:
        raise SystemExit(1)

    if not args.namespace:
        libraries = LIBRARIES
    else:
        libraries = []
        for l in LIBRARIES:
            if l.namespace in args.namespace:
                libraries.append(l)
        if len(args.namespace) != len(libraries):
            print("Invalid namespaces in %s" % args.namespace)
            raise SystemExit(1)

    for lib in libraries:
        pages, keywords = fetch_pages(lib)
        mapping = {}
        for names, page in pool.imap_unordered(
                fetch_page, [(lib, p, keywords) for p in pages]):
            print(page)
            mapping.update(names)

        ns = lib.namespace
        namespace, version = ns.split("-")
        with open(get_docref_path(namespace, version), "wb") as h:
            h.write(
                json.dumps(mapping, sort_keys=True, indent=4).encode("utf-8"))


if __name__ == "__main__":
    sys.exit(main(sys.argv))
